{"paragraphs":[{"text":"%md ##Event Statistics using Scala","user":"anonymous","dateUpdated":"2018-02-12T07:00:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>##Event Statistics using Scala</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518418808116_846552530","id":"20170126-084346_411967885","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:00:21+0000","dateFinished":"2018-02-12T07:00:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9711"},{"title":"Event Statistics using Scala","text":"// any import statements go here\nimport org.apache.spark.rdd.RDD\nimport org.apache.commons.io.IOUtils\nimport java.text.SimpleDateFormat\nimport java.util.Date\nimport java.net.URL\nimport java.nio.charset.Charset\nimport org.apache.spark.sql._","user":"anonymous","dateUpdated":"2018-02-12T07:27:17+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":false,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport org.apache.commons.io.IOUtils\nimport java.text.SimpleDateFormat\nimport java.util.Date\nimport java.net.URL\nimport java.nio.charset.Charset\nimport org.apache.spark.sql._\n"}]},"apps":[],"jobName":"paragraph_1518418808117_846167782","id":"20170125-092928_572765858","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:27:18+0000","dateFinished":"2018-02-12T07:27:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9712"},{"title":"Then, load data. We uploaded the data on S3 for easier loading","text":"// load raw data\n\ndef loadFromUrl(url:String) = \n    sc.parallelize(\n        IOUtils.toString(\n            new URL(url),\n            Charset.forName(\"utf8\")).split(\"\\n\"))\n            \nval events = loadFromUrl(\"http://sunlab.org/download/course/hw2/events.csv\")\nval mortality = loadFromUrl(\"http://sunlab.org/download/course/hw2/mortality.csv\")\n","user":"anonymous","dateUpdated":"2018-02-12T07:27:31+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"loadFromUrl: (url: String)org.apache.spark.rdd.RDD[String]\nevents: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[0] at parallelize at <console>:39\nmortality: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[1] at parallelize at <console>:39\n"}]},"apps":[],"jobName":"paragraph_1518418808117_846167782","id":"20170125-102007_1054430570","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:27:31+0000","dateFinished":"2018-02-12T07:28:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9713"},{"text":"import java.util.Date\n// Define case class\ncase class Event(patientId: String, category: String, event: String, date: java.util.Date, value: Double)\ncase class Mortality(patientId: String, mortality_date:  java.util.Date, label: Double)\n","user":"anonymous","dateUpdated":"2018-02-12T07:28:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.util.Date\ndefined class Event\ndefined class Mortality\n"}]},"apps":[],"jobName":"paragraph_1518418808117_846167782","id":"20170125-093656_1081259042","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:28:32+0000","dateFinished":"2018-02-12T07:28:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9714"},{"text":"\n// Define date format\nval dateFormat = new SimpleDateFormat(\"yyyy-MM-dd\")","user":"anonymous","dateUpdated":"2018-02-12T07:28:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dateFormat: java.text.SimpleDateFormat = java.text.SimpleDateFormat@f67a0200\n"}]},"apps":[],"jobName":"paragraph_1518418808117_846167782","id":"20170205-182828_2037956217","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:28:35+0000","dateFinished":"2018-02-12T07:28:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9715"},{"text":"\n// Load events & mortality into their corresponding RDD\n//val eventsRDD: RDD[Event] = events.map(s=>s.split(\",\")).map(s=>Event(s(0), s(1), s(2),dateFormat.parse(s(3).asInstanceOf[String]), s(4).toDouble))\nval eventsRDD: RDD[Event] = events.map(s=>s.split(\",\")).map(s=>Event(s(0), s(1), s(2),dateFormat.parse(s(3).asInstanceOf[String]), if (s.length > 4 ) s(4).toDouble else 0.0 ))\nval mortalityRDD: RDD[Mortality] = mortality.map(s=>s.split(\",\")).map(s=>Mortality(s(0), dateFormat.parse(s(1).asInstanceOf[String]), s(2).toDouble))","user":"anonymous","dateUpdated":"2018-02-12T07:28:39+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"eventsRDD: org.apache.spark.rdd.RDD[Event] = MapPartitionsRDD[3] at map at <console>:48\nmortalityRDD: org.apache.spark.rdd.RDD[Mortality] = MapPartitionsRDD[5] at map at <console>:45\n"}]},"apps":[],"jobName":"paragraph_1518418808120_845013535","id":"20170125-103206_1230836042","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:28:39+0000","dateFinished":"2018-02-12T07:28:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9716"},{"title":"Event count is defined as the number of events recorded for a given patient","text":"def event_count_metrics(eve: RDD[(Event)], mor: RDD[(Mortality)]) : (Double, Double, Double, Double, Double, Double) = {\n    \n    // TODO : Implement this function to return the event count metrics.\n    \n    val keyedEventsRDD: RDD[(String, Event)] = eventsRDD.map(s=>(s.patientId,s))  \n    val keyedMortalityRDD: RDD[(String, Mortality)] = mortalityRDD.map(s=>(s.patientId,s))\n    val joinedRDD: RDD[(String,(Event,Option[Mortality]))] = keyedEventsRDD.leftOuterJoin(keyedMortalityRDD)\n    val deadRDD: RDD[(String,(Event,Option[Mortality]))] = joinedRDD.filter(s=> s._2._2.isDefined)\n    val aliveRDD: RDD[(String,(Event,Option[Mortality]))] = joinedRDD.filter(s=> !s._2._2.isDefined)\n    \n    val deadcountList = deadRDD.map{x=>(x._1,x._2._1)}.groupBy(x=>x._1).mapValues(_.size)\n    val alivecountList = aliveRDD.map{x=>(x._1,x._2._1)}.groupBy(x=>x._1).mapValues(_.size)\n    val deadcount=deadcountList.map(x=>x._2.toDouble)\n    val alivecount=alivecountList.map(x=>x._2.toDouble)\n    \n    val avg_dead_event_count = deadcount.mean()\n    val max_dead_event_count = deadcount.max()\n    val min_dead_event_count = deadcount.min()\n    val avg_alive_event_count = alivecount.mean()\n    val max_alive_event_count = alivecount.max()\n    val min_alive_event_count = alivecount.min()\n\n    \n    (avg_dead_event_count, max_dead_event_count, min_dead_event_count, avg_alive_event_count, max_alive_event_count, min_alive_event_count)\n}","user":"anonymous","dateUpdated":"2018-02-12T07:35:16+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","colWidth":12,"title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"event_count_metrics: (eve: org.apache.spark.rdd.RDD[Event], mor: org.apache.spark.rdd.RDD[Mortality])(Double, Double, Double, Double, Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1518418808120_845013535","id":"20170125-163824_794924019","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:28:46+0000","dateFinished":"2018-02-12T07:28:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9717"},{"title":"Encounter count is defined as the count of unique dates on which a given patient visited the ICU. ","text":"def encounter_count_metrics(eve: RDD[(Event)], mor: RDD[(Mortality)]) : (Double, Double, Double, Double, Double, Double) = {\n    \n    // TODO : Implement this function to return the encounter count metrics.\n    \n    val keyedEventsRDD: RDD[(String, Event)] = eventsRDD.map(s=>(s.patientId,s))  \n    val keyedMortalityRDD: RDD[(String, Mortality)] = mortalityRDD.map(s=>(s.patientId,s))\n    val joinedRDD: RDD[(String,(Event,Option[Mortality]))] = keyedEventsRDD.leftOuterJoin(keyedMortalityRDD)\n    val deadRDD: RDD[(String,(Event,Option[Mortality]))] = joinedRDD.filter(s=> s._2._2.isDefined)\n    val aliveRDD: RDD[(String,(Event,Option[Mortality]))] = joinedRDD.filter(s=> !s._2._2.isDefined)\n    \n    val deadencounterList = deadRDD.map(x=>{val event=x._2._1; val patientid=event.patientId; val time=event.date; (patientid,time)}).distinct.groupBy(x=>x._1).mapValues(_.size)\n    val aliveencounterList = aliveRDD.map(x=>{val event=x._2._1; val patientid=event.patientId; val time=event.date; (patientid,time)}).distinct.groupBy(x=>x._1).mapValues(_.size)\n    val deadencounter=deadencounterList.map(x=>x._2.toDouble)\n    val aliveencounter=aliveencounterList.map(x=>x._2.toDouble)\n    \n    val avg_dead_encounter_count = deadencounter.mean()\n    val max_dead_encounter_count = deadencounter.max()\n    val min_dead_encounter_count = deadencounter.min()\n    val avg_alive_encounter_count = aliveencounter.mean()\n    val max_alive_encounter_count = aliveencounter.max()\n    val min_alive_encounter_count = aliveencounter.min()\n    \n\n    \n    (avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count)\n}","user":"anonymous","dateUpdated":"2018-02-12T07:35:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"encounter_count_metrics: (eve: org.apache.spark.rdd.RDD[Event], mor: org.apache.spark.rdd.RDD[Mortality])(Double, Double, Double, Double, Double, Double)\n"}]},"apps":[],"jobName":"paragraph_1518418808121_844628786","id":"20170126-094037_1369751422","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:28:52+0000","dateFinished":"2018-02-12T07:28:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9718"},{"title":"Testing Event Count - Don't change this cell","text":"\nval (avg_dead_event_count, max_dead_event_count, min_dead_event_count, avg_alive_event_count, max_alive_event_count, min_alive_event_count) = \nevent_count_metrics(eventsRDD, mortalityRDD)","user":"anonymous","dateUpdated":"2018-02-12T07:29:06+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avg_dead_event_count: Double = 1027.7385229540914\nmax_dead_event_count: Double = 16829.0\nmin_dead_event_count: Double = 2.0\navg_alive_event_count: Double = 683.1552587646087\nmax_alive_event_count: Double = 12627.0\nmin_alive_event_count: Double = 1.0\n"}]},"apps":[],"jobName":"paragraph_1518418808122_845783033","id":"20170125-164106_1373358169","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:29:06+0000","dateFinished":"2018-02-12T07:31:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9719"},{"title":"Populate the correct values in df_events dataframe","text":"case class eventRecord(Average_Event: Double , Max_Event: Double, Min_Event: Double, Mortality: String) \n// val df_events = Seq(eventRecord(50.0, 80.0, 20.0, \"Alive\"), eventRecord(100.0, 160.0, 60.0, \"Dead\")).toDF \n\n// TODO - Fill in the correct values of minimum, maximum and average events for Alive and Dead Patients \nval df_events = Seq(eventRecord(avg_alive_event_count, max_alive_event_count, min_alive_event_count, \"Alive\"), eventRecord(avg_dead_event_count, max_dead_event_count, min_alive_event_count, \"Dead\")).toDF\ndf_events.registerTempTable(\"df_events\")\n","user":"anonymous","dateUpdated":"2018-02-12T07:38:49+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class eventRecord\ndf_events: org.apache.spark.sql.DataFrame = [Average_Event: double, Max_Event: double ... 2 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1518418808122_845783033","id":"20170126-095056_275615884","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:38:49+0000","dateFinished":"2018-02-12T07:38:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9720"},{"title":"Plot Event Count Grouped by Dead/Alive","text":"%sql\nselect * from df_events","user":"anonymous","dateUpdated":"2018-02-12T07:42:26+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"values":[{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}]},"helium":{}}},"graph":{"mode":"table","height":300,"optionOpen":true,"keys":[{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}],"values":[{"name":"Max_Event","index":1,"aggr":"sum"},{"name":"Average_Event","index":0,"aggr":"sum"},{"name":"Min_Event","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"scatter":{"xAxis":{"name":"Average_Event","index":0,"aggr":"sum"},"yAxis":{"name":"Max_Event","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Average_Event\tMax_Event\tMin_Event\tMortality\n683.1552587646087\t12627.0\t1.0\tAlive\n1027.7385229540914\t16829.0\t1.0\tDead\n"}]},"apps":[],"jobName":"paragraph_1518418808122_845783033","id":"20170127-103258_1100387642","dateCreated":"2018-02-12T07:00:08+0000","dateStarted":"2018-02-12T07:39:10+0000","dateFinished":"2018-02-12T07:39:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9721"},{"title":"Testing Encounter Count - Don't change any cell starting from this one","text":"val  (avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count) = encounter_count_metrics(eventsRDD, mortalityRDD)","dateUpdated":"2018-02-12T07:49:33+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518418808123_845398284","id":"20170126-085842_586212247","dateCreated":"2018-02-12T07:00:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9722","user":"anonymous","dateFinished":"2018-02-12T07:50:40+0000","dateStarted":"2018-02-12T07:49:33+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avg_dead_encounter_count: Double = 24.839321357285407\nmax_dead_encounter_count: Double = 375.0\nmin_dead_encounter_count: Double = 1.0\navg_alive_encounter_count: Double = 18.69549248747911\nmax_alive_encounter_count: Double = 391.0\nmin_alive_encounter_count: Double = 1.0\n"}]}},{"title":"Populate the correct values in df_encounters dataframe","text":"case class encounterRecord(Average_Encounter: Double , Max_Encounter: Double, Min_Encounter: Double, Mortality: String)\n\nval df_encounter = Seq(encounterRecord(avg_alive_encounter_count, max_alive_encounter_count, min_alive_encounter_count, \"Alive\"), encounterRecord(avg_dead_encounter_count, max_dead_encounter_count, min_dead_encounter_count, \"Dead\")).toDF \n\n// TODO - Fill in the correct values of minimum, maximum and average events for Alive and Dead Patients \n//val df_encounter = Seq(encounterRecord(0.0, 0.0, 0.0, \"Alive\"), encounterRecord(0.0, 0.0, 0.0, \"Dead\")).toDF\ndf_encounter.registerTempTable(\"df_encounter\")\n","dateUpdated":"2018-02-12T07:53:25+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518418808123_845398284","id":"20170127-104258_320884595","dateCreated":"2018-02-12T07:00:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9723","user":"anonymous","dateFinished":"2018-02-12T07:53:29+0000","dateStarted":"2018-02-12T07:53:25+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defined class encounterRecord\ndf_encounter: org.apache.spark.sql.DataFrame = [Average_Encounter: double, Max_Encounter: double ... 2 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"title":"Plot Encounter Count Grouped by Dead/Alive","text":"%sql\nselect * from df_encounter ","dateUpdated":"2018-02-12T07:54:14+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"values":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}]},"helium":{}}},"graph":{"mode":"table","height":300,"optionOpen":true,"keys":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}],"values":[{"name":"Max_Encounter","index":1,"aggr":"sum"},{"name":"Average_Encounter","index":0,"aggr":"sum"},{"name":"Min_Encounter","index":2,"aggr":"sum"}],"groups":[{"name":"Mortality","index":3,"aggr":"sum"}],"scatter":{"xAxis":{"name":"Average_Encounter","index":0,"aggr":"sum"},"yAxis":{"name":"Max_Encounter","index":1,"aggr":"sum"}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518418808124_843474539","id":"20170127-113147_1780103981","dateCreated":"2018-02-12T07:00:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9724","user":"anonymous","dateFinished":"2018-02-12T07:53:43+0000","dateStarted":"2018-02-12T07:53:43+0000","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Average_Encounter\tMax_Encounter\tMin_Encounter\tMortality\n18.69549248747911\t391.0\t1.0\tAlive\n24.839321357285407\t375.0\t1.0\tDead\n"}]}},{"text":"","dateUpdated":"2018-02-12T07:56:06+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518418808124_843474539","id":"20170127-113337_1396101507","dateCreated":"2018-02-12T07:00:08+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:9725","user":"anonymous"}],"name":"Arindam_Zeppelin","id":"2D6AHJS47","angularObjects":{"2D8K7Y5TY:shared_process":[],"2D8FQZY8B:shared_process":[],"2D6D841S4:shared_process":[],"2D77N4QTU:shared_process":[],"2D5TBA5YV:shared_process":[],"2D59EDRSW:shared_process":[],"2D5JQQBSV:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}